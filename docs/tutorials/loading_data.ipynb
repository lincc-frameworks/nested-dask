{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data into Nested-Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import nested_dask as nd\n",
    "import nested_pandas as npd\n",
    "from nested_dask import read_parquet\n",
    "from nested_dask.datasets import generate_parquet_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Nested-Pandas\n",
    "\n",
    "Nested-Dask can load data from Nested-Pandas `NestedFrame` objects by using the `from_pandas` class function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Nested-Pandas NestedFrame\n",
    "nf = npd.NestedFrame(data={\"a\": [1, 2, 3], \"b\": [2, 4, 6]}, index=[0, 1, 2])\n",
    "\n",
    "nested = npd.NestedFrame(\n",
    "    data={\"c\": [0, 2, 4, 1, 4, 3, 1, 4, 1], \"d\": [5, 4, 7, 5, 3, 1, 9, 3, 4]},\n",
    "    index=[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
    ")\n",
    "\n",
    "nf = nf.add_nested(nested, \"nested\")\n",
    "\n",
    "# Convert to Nested-Dask NestedFrame\n",
    "nf = nd.NestedFrame.from_pandas(nf)\n",
    "nf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from Parquet \n",
    "\n",
    "For larger datasets, we support loading data from parquet files.\n",
    "\n",
    "In the following cell, we generate a series of temporary parquet files with random data, and ingest them with the `read_parquet` method.\n",
    "\n",
    "Then we use `read_parquet` to read each layer's parquet files into their own `NestedFrame`. Then we again use `add_nested` to pack these into a single `NestedFrame`, `nf`.\n",
    "\n",
    "Note that for each layer of our `NestedFrame` we expect a directory of parquet files where each file will be its own [Dask partition](https://docs.dask.org/en/stable/dataframe-design.html#dataframe-design-partitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = None\n",
    "\n",
    "# Note: that we use the `tempfile` module to create and then cleanup a temporary directory.\n",
    "# You can of course remove this and use your own directory and real files on your system.\n",
    "with tempfile.TemporaryDirectory() as temp_path:\n",
    "    # Generates parquet files with random data within our temporary directory.\n",
    "    generate_parquet_file(\n",
    "        10,  # The number of rows to generated in the base layer\n",
    "        {\n",
    "            \"nested1\": 100,  # Generate a nested layer named 'nested1' with 100 rows.\n",
    "            \"nested2\": 10,\n",
    "        },  # Generate a nested layer nameed 'nested2' with 10 rows.\n",
    "        temp_path,  # The root temporary directory to store our generated parquet files.\n",
    "        npartitions=5,  # The number of Dask partitions for each layer.\n",
    "        file_per_layer=True,  # Generates a unique directory of parquet files for each layer\n",
    "    )\n",
    "\n",
    "    # Note that each layer of our NestedFrame will be in its own directory,\n",
    "    # with a parquet file for each Dask partition.\n",
    "    parquet_dirs = [\n",
    "        os.path.join(temp_path, \"base\"),\n",
    "        os.path.join(temp_path, \"nested1\"),\n",
    "        os.path.join(temp_path, \"nested2\"),\n",
    "    ]\n",
    "    for path in parquet_dirs:\n",
    "        print(f\"Directory {path} has the following parquet files {os.listdir(path)}.\")\n",
    "\n",
    "    # Create a single NestedFrame for our base layer from the directory containing the parquet files\n",
    "    # for each of its partitions.\n",
    "    nf = read_parquet(path=os.path.join(temp_path, \"base\"))\n",
    "\n",
    "    # Read the nested layers from their respective directories.\n",
    "    nested1 = read_parquet(os.path.join(temp_path, \"nested1\"))\n",
    "    nested1 = nested1.persist()\n",
    "    nested2 = read_parquet(os.path.join(temp_path, \"nested2\"))\n",
    "    nested2 = nested2.persist()\n",
    "\n",
    "    # Add the nested layers to the NestedFrame.\n",
    "    nf = nf.add_nested(nested1, \"nested1\")\n",
    "    nf = nf.add_nested(nested2, \"nested2\")\n",
    "\n",
    "    # Here we have Dask 'persist' the data in memory now so that we don't have to read it from\n",
    "    # the source parquet files again (as it may try to do due to lazy evaluation).\n",
    "    # This is particularly useful since it forces Dask to read the data\n",
    "    # from the temporary parquet files before they are deleted rather than\n",
    "    nf = nf.persist()\n",
    "\n",
    "nf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can use Dask's `compute()` to fully evaluate our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving NestedFrames to Parquet Files\n",
    "\n",
    "Additionally we can save an existing `NestedFrame` as a collection of parquet files using `NestedFrame.to_parquet`\n",
    "\n",
    "We save each layer to its own directory, and each Dask partition for that layer to its own parquet file within that directory.\n",
    "\n",
    "The base layer will be outputted to a directory named \"base\", and each nested layer will be written to a directory based on its respective column name. \n",
    "\n",
    "So the nested layer in column `nested1` will be written to directory \"nested1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_nf = None\n",
    "\n",
    "# Note: that we use the `tempfile` module to create and then cleanup a temporary directory.\n",
    "# You can of course remove this and use your own directory and real files on your system.\n",
    "with tempfile.TemporaryDirectory() as temp_path:\n",
    "    nf.to_parquet(\n",
    "        temp_path,  # The directory to save our output parquet files.\n",
    "        by_layer=True,  # Each layer will be saved in its own sub directory.\n",
    "    )\n",
    "    # List the files in temp_path to ensure they were saved correctly.\n",
    "    print(\"The NestedFrame was saved to the following directories :\", os.listdir(temp_path))\n",
    "\n",
    "    # Read the NestedFrame back in from our saved parquet files.\n",
    "    restored_nf = read_parquet(os.path.join(temp_path, \"base\"))\n",
    "\n",
    "    # Read the nested layers from their respective directories.\n",
    "    nested1 = read_parquet(os.path.join(temp_path, \"nested1\"))\n",
    "    nested2 = read_parquet(os.path.join(temp_path, \"nested2\"))\n",
    "\n",
    "    # Add the nested layers to the NestedFrame.\n",
    "    restored_nf = restored_nf.add_nested(nested1, \"nested1\")\n",
    "    restored_nf = restored_nf.add_nested(nested2, \"nested2\")\n",
    "\n",
    "    # Here we have Dask 'persist' the data in memory now so that we don't have to read it from\n",
    "    # the source parquet files again (as it may try to do due to lazy evaluation).\n",
    "    # This is particularly useful since it forces Dask to read the data\n",
    "    # from the temporary parquet files before they are deleted rather than\n",
    "    restored_nf = restored_nf.persist()\n",
    "\n",
    "restored_nf  # our dataframe is restored from our saved parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_nf.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
